{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DOC2VEC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EShoukry/AI-StoryGeneration/blob/master/DOC2VEC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_7HBBx39x4W",
        "colab_type": "text"
      },
      "source": [
        "# Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFoZIH3N9x4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "#import Keras library\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import LSTM, Input, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.metrics import categorical_accuracy\n",
        "!pip install spacy\n",
        "#import spacy, and spacy french model\n",
        "# spacy is used to work on text\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "#import other libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import codecs\n",
        "import collections\n",
        "from six.moves import cPickle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3yVt0kP9x4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_directory = ''\n",
        "save_directory = ''\n",
        "rnn_size = 128\n",
        "batch_size = 30\n",
        "seq_length = 15\n",
        "num_epochs = 8\n",
        "learning_rate = 0.001\n",
        "input_file = [\"test.txt\"]\n",
        "vocab_file = os.path.join(save_directory, \"words_vocab.pkl\")\n",
        "sequences_step = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b42Dq6Ic9x4d",
        "colab_type": "text"
      },
      "source": [
        "# Method to Create Wordlist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYa-lS0g9x4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_wordlist(doc):\n",
        "    word_list = []\n",
        "    for word in doc:\n",
        "        if word.text not in (\"\\n\", \"\\n\\n\", \"Armor\", \"Class\", \"Speed\"):\n",
        "            word_list.append(word.text.lower())\n",
        "    return word_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzIxbwUI9x4g",
        "colab_type": "text"
      },
      "source": [
        "# Build Wordlist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJQJUQfp9x4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_words = []\n",
        "\n",
        "input_file = 'test.txt'\n",
        "with codecs.open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = f.read()\n",
        "x_text = data.split()\n",
        "doc = nlp(data)\n",
        "w = create_wordlist(doc)\n",
        "list_of_words = list_of_words + w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t-4aBzA9x4m",
        "colab_type": "text"
      },
      "source": [
        "# Create Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meYiyequ9x4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "322a1d61-881c-43d1-e749-83669efbd073"
      },
      "source": [
        "word_counts = collections.Counter(list_of_words)\n",
        "\n",
        "# Mapping from index to word : that's the vocabulary\n",
        "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
        "vocabulary_inv = list(sorted(vocabulary_inv))\n",
        "\n",
        "# Mapping from word to index\n",
        "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "words = [x[0] for x in word_counts.most_common()]\n",
        "\n",
        "#size of the vocabulary\n",
        "vocab_size = len(words)\n",
        "print(\"vocab size: \", vocab_size)\n",
        "\n",
        "#save the words and vocabulary\n",
        "with open(os.path.join(vocab_file), 'wb') as f:\n",
        "    cPickle.dump((words, vocab, vocabulary_inv), f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size:  6929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9VBZR-j9x4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edb5e96c-574f-4f2e-8cfd-a9c28ec5d502"
      },
      "source": [
        "#create sequences\n",
        "sequences = []\n",
        "next_words = []\n",
        "seq_length = 15\n",
        "for i in range(0, len(list_of_words) - seq_length, sequences_step):\n",
        "    sequences.append(list_of_words[i: i + seq_length])\n",
        "    next_words.append(list_of_words[i + seq_length])\n",
        "\n",
        "print('nb sequences:', len(sequences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 118020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG2J6iKu9x4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n",
        "for i, sentence in enumerate(sequences):\n",
        "    for t, word in enumerate(sentence):\n",
        "        X[i, t, vocab[word]] = 1\n",
        "    y[i, vocab[next_words[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}