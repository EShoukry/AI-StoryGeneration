{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EShoukry/AI-StoryGeneration/blob/master/Training_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Am0Q-1eEa6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "import codecs\n",
        "import collections\n",
        "from six.moves import cPickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fls5VONicWqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'drive/My Drive/Colab Notebooks/'# data directory containing input.txt\n",
        "save_dir = 'drive/My Drive/Colab Notebooks/' # directory to store models\n",
        "rnn_size = 128 # size of RNN\n",
        "batch_size = 30 # minibatch size\n",
        "seq_length = 15 # sequence length\n",
        "num_epochs = 8 # number of epochs\n",
        "learning_rate = 0.001 #learning rate\n",
        "sequences_step = 1 #step to create sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgU0JK_Xcqeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_file = os.path.join(data_dir, \"MonsterManual.txt\")\n",
        "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBSWYBa7cttm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open(input_file, \"r\", encoding=None) as f:\n",
        "    data = f.read()\n",
        "\n",
        "x_text = data.split()\n",
        "x_text = sorted(x_text)\n",
        "x_text = x_text[16408:178075]\n",
        "print(x_text)\n",
        "print(len(x_text))\n",
        "for w in x_text:\n",
        "  if w.isalpha() == False:\n",
        "    x_text.remove(w)\n",
        " \n",
        "x_text = [x.lower() for x in x_text]\n",
        "print(len(x_text))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNN3V93akr8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esMS_iiYcu4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counts = collections.Counter(x_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMW8odb1cwBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
        "vocabulary_inv = list(sorted(vocabulary_inv))\n",
        "print(vocabulary_inv)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPYet9l2cxyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "words = [x[0] for x in word_counts.most_common()]\n",
        "\n",
        "#size of the vocabulary\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "#save the words and vocabulary\n",
        "with open(os.path.join(vocab_file), 'wb') as f:\n",
        "    cPickle.dump((words, vocab, vocabulary_inv), f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyD0yfM_czn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = []\n",
        "next_words = []\n",
        "for i in range(0, len(x_text) - seq_length, sequences_step):\n",
        "    sequences.append(x_text[i: i + seq_length])\n",
        "    next_words.append(x_text[i + seq_length])\n",
        "\n",
        "print('nb sequences:', len(sequences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lRpXV8Hc1Dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Vectorization.')\n",
        "X = np.empty((len(sequences), seq_length, vocab_size), dtype=np.bool)\n",
        "print('Complete')\n",
        "y = np.empty((len(sequences), vocab_size), dtype=np.bool)\n",
        "print('Complete')\n",
        "for i, sentence in enumerate(sequences):\n",
        "    for t, word in enumerate(sentence):\n",
        "        X[i, t, vocab[word]] = 1\n",
        "    y[i, vocab[next_words[i]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFN1zoERvBym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Build LSTM model.')\n",
        "model = Sequential()\n",
        "model.add(LSTM(rnn_size, input_shape=(seq_length, vocab_size)))\n",
        "model.add(Dense(vocab_size))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "#fit the model\n",
        "model.fit(X, y,batch_size=batch_size,epochs=num_epochs)\n",
        "\n",
        "#save the model\n",
        "model.save(save_dir + \"/\" + 'my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}